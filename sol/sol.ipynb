{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "Assume only few spoofing attacks\n",
    "\n",
    "Synchronize clocks assuming all broadcast locations are correct\n",
    "\n",
    "Estimate positions for messages based on sensor timestamps\n",
    "\n",
    "Remove messages with high deviations between broadcast locations and estimated locations\n",
    "\n",
    "Re-synchronize clocks and re-check broadcast locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1946c9c8965c479c98fe6791adfe0692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1367359\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 1101115, 'irrelevant': 207540, 'invalid_msg_pos': 1980, 'invalid_sensor_pos_lon': 6007, 'unknown_sensortype_GRX1090': 3328, 'invalid_sensor_pos_lat': 7395, 'null_values': 7731})\n",
      "sum discarded: 1335096\n",
      "total: 3045417\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 2451555, 'irrelevant': 463519, 'invalid_msg_pos': 2069, 'invalid_sensor_pos_lon': 13312, 'unknown_sensortype_GRX1090': 7347, 'invalid_sensor_pos_lat': 16543, 'null_values': 16797})\n",
      "sum discarded: 2971142\n",
      "total: 4348773\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 3500651, 'irrelevant': 661724, 'invalid_msg_pos': 2095, 'invalid_sensor_pos_lon': 18986, 'unknown_sensortype_GRX1090': 10487, 'invalid_sensor_pos_lat': 23816, 'null_values': 23909})\n",
      "sum discarded: 4241668\n",
      "total: 5972814\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 4807050, 'irrelevant': 909716, 'invalid_msg_pos': 2144, 'invalid_sensor_pos_lon': 25962, 'unknown_sensortype_GRX1090': 14401, 'invalid_sensor_pos_lat': 32818, 'null_values': 32953})\n",
      "sum discarded: 5825044\n",
      "total: 7495692\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 6036954, 'irrelevant': 1137740, 'invalid_msg_pos': 2246, 'invalid_sensor_pos_lon': 32293, 'unknown_sensortype_GRX1090': 18058, 'invalid_sensor_pos_lat': 41254, 'null_values': 41593})\n",
      "sum discarded: 7310138\n",
      "total: 9472118\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 7650238, 'irrelevant': 1419814, 'invalid_msg_pos': 2312, 'invalid_sensor_pos_lon': 40084, 'unknown_sensortype_GRX1090': 22766, 'invalid_sensor_pos_lat': 51547, 'null_values': 53141})\n",
      "sum discarded: 9239902\n",
      "total: 11028936\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 8922397, 'irrelevant': 1640006, 'invalid_msg_pos': 2489, 'invalid_sensor_pos_lon': 46187, 'unknown_sensortype_GRX1090': 26646, 'invalid_sensor_pos_lat': 59903, 'null_values': 61956})\n",
      "sum discarded: 10759584\n",
      "total: 12796687\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 10369164, 'irrelevant': 1889522, 'invalid_msg_pos': 2532, 'invalid_sensor_pos_lon': 52371, 'unknown_sensortype_GRX1090': 31004, 'invalid_sensor_pos_lat': 69114, 'null_values': 71824})\n",
      "sum discarded: 12485531\n",
      "total: 14836092\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 12034227, 'irrelevant': 2179921, 'invalid_msg_pos': 2571, 'invalid_sensor_pos_lon': 61314, 'unknown_sensortype_GRX1090': 35901, 'invalid_sensor_pos_lat': 79712, 'null_values': 83098})\n",
      "sum discarded: 14476744\n",
      "total: 16474933\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 13379016, 'irrelevant': 2408947, 'invalid_msg_pos': 2656, 'invalid_sensor_pos_lon': 68252, 'unknown_sensortype_GRX1090': 39535, 'invalid_sensor_pos_lat': 88100, 'null_values': 92051})\n",
      "sum discarded: 16078557\n",
      "total: 17887858\n",
      "defaultdict(<class 'int'>, {'bad_sensortype': 14537780, 'irrelevant': 2607472, 'invalid_msg_pos': 2688, 'invalid_sensor_pos_lon': 74210, 'unknown_sensortype_GRX1090': 42631, 'invalid_sensor_pos_lat': 95554, 'null_values': 99759})\n",
      "sum discarded: 17460094\n",
      "Sensors: 111\n",
      "Relevant Received Messages: 107217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import position_estimator\n",
    "from position_estimator import GeoPoint\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "DATA_LOCATION = \"E:/thesis_data/1hour_complete_22_01_10_05/\"\n",
    "#DATA_LOCATION = \"../raw_data/1hour/\"\n",
    "\n",
    "sensors = set()\n",
    "#sensors_rev = dict()\n",
    "received = defaultdict(lambda: { \"sensors\": list(), \"timeAtServer_min\": 1E12, \"timeAtServer_max\": 0 })\n",
    "sensor_received = defaultdict(list)\n",
    "\n",
    "MSG_CUTOFF = 100000\n",
    "#MSG_CUTOFF = 1\n",
    "\n",
    "pbar = tqdm(total=MSG_CUTOFF, mininterval=1)\n",
    "pbar.update(0)\n",
    "\n",
    "discarded = defaultdict(int)\n",
    "total = 0\n",
    "\n",
    "timeAtServer_min = 1e12\n",
    "timeAtServer_max = 0\n",
    "\n",
    "for file in os.listdir(DATA_LOCATION):\n",
    "    assert re.match(r\"^part-\\d{5}$\", file)\n",
    "    pbar.set_description(file)\n",
    "    pbar.refresh()\n",
    "    with open(os.path.join(DATA_LOCATION, file), \"r\") as f:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            continue\n",
    "        assert line == \"sensorType,sensorLatitude,sensorLongitude,sensorAltitude,timeAtServer,timeAtSensor,timestamp,rawMessage,sensorSerialNumber,RSSIPacket,RSSIPreamble,SNR,confidence\\n\"\n",
    "        while (line := f.readline().strip()):\n",
    "            sensorType,sensorLatitude,sensorLongitude,sensorAltitude,timeAtServer,timeAtSensor,timestamp,rawMessage,sensorSerialNumber,RSSIPacket,RSSIPreamble,SNR,confidence = line.split(',')\n",
    "\n",
    "            total += 1\n",
    "\n",
    "            if sensorType in ['SBS-3', 'OpenSky', 'dump1090']:\n",
    "                discarded['bad_sensortype'] += 1\n",
    "                continue\n",
    "\n",
    "            if not position_estimator.is_relevant(rawMessage):\n",
    "                discarded[\"irrelevant\"] += 1\n",
    "                continue\n",
    "\n",
    "            if 'null' in [sensorLatitude, sensorLongitude, sensorAltitude, timeAtSensor, timestamp]:\n",
    "                discarded[\"null_values\"] += 1\n",
    "                continue\n",
    "            \n",
    "            sensorLatitude = float(sensorLatitude)\n",
    "            sensorLongitude = float(sensorLongitude)\n",
    "            sensorAltitude = float(sensorAltitude)\n",
    "            timeAtSensor = float(timeAtSensor)\n",
    "            timestamp = float(timestamp)\n",
    "\n",
    "            timeAtServer = float(timeAtServer)\n",
    "            timeAtServer_max = max(timeAtServer_max, timeAtServer)\n",
    "            timeAtServer_min = min(timeAtServer_min, timeAtServer)\n",
    "\n",
    "            # convert timestamps according to raw_data.pdf\n",
    "            if sensorType == 'dump1090':\n",
    "                timeAtSensor *= 89.47848533333334 # 2**30 / 12e6\n",
    "                timeAtSensor += timestamp / 12e6\n",
    "                assert 0 <= timestamp / 12e6 < 89.47848533333335\n",
    "            elif sensorType == 'Radarcape':\n",
    "                timeAtSensor += timestamp / 1e9\n",
    "            else:\n",
    "                discarded[f'unknown_sensortype_{sensorType}'] += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "            #print(timestamp, timestamp/2**30)\n",
    "            #assert 0 <= timestamp / 2**30 < 1\n",
    "\n",
    "            #timeAtSensor += timestamp / 2**30\n",
    "\n",
    "            # limit to europe for now\n",
    "            if not 35 < sensorLatitude < 75:\n",
    "                discarded[\"invalid_sensor_pos_lat\"] += 1\n",
    "                continue\n",
    "            elif not -10 < sensorLongitude < 40:\n",
    "                discarded[\"invalid_sensor_pos_lon\"] += 1\n",
    "                continue\n",
    "\n",
    "            if not (sensorLatitude and sensorLongitude):\n",
    "                discarded[\"invalid_sensor_pos_zero\"] += 1\n",
    "                continue\n",
    "\n",
    "            if not \"pos\" in received[rawMessage]:\n",
    "                try:\n",
    "                    received[rawMessage][\"pos\"] = position_estimator.get_announced_pos(rawMessage, timeAtSensor)\n",
    "                    assert -90 <= received[rawMessage][\"pos\"].lat <= 90\n",
    "                    assert -180 <= received[rawMessage][\"pos\"].lon <= 180\n",
    "                except:\n",
    "                    discarded[\"invalid_msg_pos\"] += 1\n",
    "                    #print(\"Couldn't get position :(\")\n",
    "                    del received[rawMessage]\n",
    "                    continue\n",
    "\n",
    "            received[rawMessage][\"timeAtServer_min\"] = min(received[rawMessage][\"timeAtServer_min\"], timeAtServer)\n",
    "            received[rawMessage][\"timeAtServer_max\"] = max(received[rawMessage][\"timeAtServer_max\"], timeAtServer)\n",
    "\n",
    "            sensor = (GeoPoint(sensorLatitude, sensorLongitude, sensorAltitude), sensorType, sensorSerialNumber)\n",
    "            if sensor not in sensors:\n",
    "                #sensors_rev[sensor] = len(sensors)\n",
    "                sensors.add(sensor)\n",
    "\n",
    "            if (timeAtSensor, sensor) not in received[rawMessage][\"sensors\"]:\n",
    "                received[rawMessage][\"sensors\"].append((timeAtSensor, sensor))\n",
    "\n",
    "            sensor_received[sensor].append((timeAtSensor, timeAtServer))\n",
    "\n",
    "    pbar.n = len(received)\n",
    "    pbar.refresh()\n",
    "\n",
    "    print(\"total:\", total)\n",
    "    print(discarded)\n",
    "    print(\"sum discarded:\", sum(discarded.values()))\n",
    "\n",
    "    if len(received) >= MSG_CUTOFF:\n",
    "        break # memory constraint\n",
    "\n",
    "\n",
    "print(\"Sensors:\", len(sensors))\n",
    "print(\"Relevant Received Messages:\", len(received))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"temp_storage/timeAtServer_minmax.pickle\", \"wb\") as f:\n",
    "    pickle.dump((timeAtServer_min, timeAtServer_max), f)\n",
    "\n",
    "with open(\"temp_storage/sensors.pickle\", \"wb\") as f:\n",
    "    pickle.dump(sensors, f)\n",
    "\n",
    "with open(\"temp_storage/received.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dict(received), f)\n",
    "\n",
    "with open(\"temp_storage/sensor_received.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dict(sensor_received), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import position_estimator\n",
    "from position_estimator import GeoPoint\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "with open(\"temp_storage/timeAtServer_minmax.pickle\", \"rb\") as f:\n",
    "    timeAtServer_min, timeAtServer_max = pickle.load(f)\n",
    "\n",
    "with open(\"temp_storage/sensors.pickle\", \"rb\") as f:\n",
    "    sensors = pickle.load(f)\n",
    "\n",
    "with open(\"temp_storage/received.pickle\", \"rb\") as f:\n",
    "    received = pickle.load(f)\n",
    "\n",
    "with open(\"temp_storage/sensor_received.pickle\", \"rb\") as f:\n",
    "    sensor_received = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors before: 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b471597d18934b1aad26b29be6440d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c354e53a43c944c0b98f61078aa92745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors after: 111\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def del_sensor(sensor):\n",
    "    assert type(sensor) is tuple\n",
    "    assert len(sensor) == 3\n",
    "    assert type(sensor[0]) is GeoPoint\n",
    "    assert type(sensor[1]) is str\n",
    "    sensors.remove(sensor)\n",
    "    del sensor\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Sensors before:\", len(sensors))\n",
    "\n",
    "faults = defaultdict(int)\n",
    "\n",
    "for sensor, timestamps in tqdm(sensor_received.items()):\n",
    "    if len(timestamps) < 2:\n",
    "        del_sensor(sensor)\n",
    "        faults[\"lt2_signals\"] += 1\n",
    "        continue\n",
    "    server_tds = [e[1] - e[0] for e in timestamps]\n",
    "    \n",
    "    #server_tds_89x = [e[1] - e[0] * 89 for e in timestamps]\n",
    "    #server_tds_895x = [e[1] - e[0] * 89.5 for e in timestamps]\n",
    "    #server_tds_90x = [e[1] - e[0] * 90 for e in timestamps]\n",
    "    #server_tds_100x = [e[1] - e[0] * 100 for e in timestamps]\n",
    "    #print(statistics.variance(server_tds), statistics.variance(server_tds_89x), statistics.variance(server_tds_895x), statistics.variance(server_tds_90x))\n",
    "    if statistics.variance(server_tds) > 50:\n",
    "        #print(sensor)\n",
    "        #print([e - server_tds[0] for e in server_tds])\n",
    "        del_sensor(sensor)\n",
    "        faults[\"variance\"] += 1\n",
    "        continue\n",
    "            \n",
    "    \n",
    "    sensor_timestamps = [e[0] for e in timestamps]\n",
    "    if max(sensor_timestamps) - min(sensor_timestamps) > timeAtServer_max - timeAtServer_min + 10:\n",
    "        #fucky timestamps\n",
    "        faults[\"timestamp_range\"] += 1\n",
    "        del_sensor(sensor)\n",
    "        continue\n",
    "    if len(set([e[0] for e in timestamps])) < len(timestamps):\n",
    "        # non-unique timestamps -> weird sensor behavior\n",
    "        #print(sensor, len(timestamps), len(set([e[0] for e in timestamps])))\n",
    "        #print(timestamps)\n",
    "        #print(set([e[0] for e in timestamps]))\n",
    "        faults[\"non_unique_timestamps\"] += 1\n",
    "        del_sensor(sensor)\n",
    "        continue\n",
    "    #for i in range(len(timestamps) - 1):\n",
    "    #    if timestamps[i][0] > timestamps[i+1][0] + 100:\n",
    "    #        del_sensor(sensor)\n",
    "    #        break\n",
    "            #print(sensor)\n",
    "            #print(i, timestamps[i], timestamps[i+1])\n",
    "            #print(\"td_sensor:\", timestamps[i][0] - timestamps[i+1][0], \"td_server:\", timestamps[i][1] - timestamps[i+1][1])\n",
    "\n",
    "print(faults)\n",
    "\n",
    "# clean up received data structure\n",
    "for msg in tqdm(received):\n",
    "    for i in reversed(range(len(received[msg][\"sensors\"]))):\n",
    "        if received[msg]['sensors'][i][1] not in sensors:\n",
    "            del received[msg]['sensors'][i]\n",
    "\n",
    "            \n",
    "\n",
    "print(\"Sensors after:\", len(sensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in sensor_received:\n",
    "    ts = defaultdict(int)\n",
    "    for t in sensor_received[sensor]:\n",
    "        ts[t[0]] += 1\n",
    "    #print(sorted(ts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages before: 107217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d45c042941f4fcfa013c88f9655c624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages after:  106816\n"
     ]
    }
   ],
   "source": [
    "# remove messages that have been sent more than once\n",
    "print(\"Messages before:\", len(received))\n",
    "for msg in tqdm(list(received.keys())):\n",
    "    if len(set([s for t, s in received[msg][\"sensors\"]])) < len(received[msg][\"sensors\"]):\n",
    "        del received[msg]\n",
    "        continue\n",
    "    if received[msg][\"timeAtServer_max\"] - received[msg][\"timeAtServer_min\"] > 5:\n",
    "        #print(\"td too high!:\", received[msg][\"timeAtServer_max\"] - received[msg][\"timeAtServer_min\"])\n",
    "        del received[msg]\n",
    "print(\"Messages after: \", len(received))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas Baege\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipyparallel\\util.py:609: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if V(jupyter_client.__version__) < V('5.0'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 16 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c070a09d2ed8403bb905b15131340476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from position_estimator import GeoPoint\n",
    "import traceback\n",
    "import ipyparallel as ipp\n",
    "import util\n",
    "C = 299792458 # light speed, meters per second\n",
    "\n",
    "n_cores = 16\n",
    "n_messages_to_process = 32\n",
    "\n",
    "time_delta = defaultdict(lambda: defaultdict(list))\n",
    "to_process = [(e['pos'], e['sensors']) for e in received.values()]#[:n_messages_to_process]\n",
    "#print(to_process[0])\n",
    "with ipp.Cluster(n=n_cores) as rc:\n",
    "    view = rc.load_balanced_view()\n",
    "    asyncresult = view.map_async(util.calc_timedeltas, *zip(*to_process))\n",
    "    #asyncresult.wait_interactive()\n",
    "    for td in tqdm(asyncresult.get()):\n",
    "        for s1 in td:\n",
    "            for s2 in td[s1]:\n",
    "                time_delta[s1][s2].extend(td[s1][s2])\n",
    "\n",
    "\n",
    "\n",
    "'''for msg in tqdm(received):\n",
    "    if \"pos\" not in received[msg] or received[msg][\"pos\"] is None:\n",
    "        continue\n",
    "\n",
    "    if len(received[msg][\"sensors\"]) < 2:\n",
    "        continue\n",
    "\n",
    "    #for t, s in list(received[msg][\"sensors\"]):\n",
    "    #    dists = sorted([s[0].dist(e[1][0]) for e in received[msg][\"sensors\"] if e[1] != s])\n",
    "    #    if dists[int(len(dists)/10)] > 1e6: # ge 1000 km\n",
    "    #        print(\"removing:\", t, s, dists)\n",
    "    #        received[msg][\"sensors\"].remove((t, s))\n",
    "\n",
    "    try:\n",
    "        sensor_dists_to_msg_origin = {x[1]: received[msg][\"pos\"].dist(x[1][0]) for x in received[msg][\"sensors\"]}\n",
    "        time_to_sensor = { s: x / C for s, x in sensor_dists_to_msg_origin.items() }\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(received[msg][\"pos\"].lat, received[msg][\"pos\"].lon, received[msg][\"pos\"].alt)\n",
    "        print({x[1]: (x[1][0].lat, x[1][0].lon, x[1][0].alt) for x in received[msg][\"sensors\"]})\n",
    "\n",
    "    for (t1, s1), (t2, s2) in itertools.combinations(received[msg][\"sensors\"], 2):\n",
    "        assert s1 != s2\n",
    "        td = (t1 - time_to_sensor[s1]) - (t2 - time_to_sensor[s2])\n",
    "        time_delta[s1][s2].append(td)\n",
    "        time_delta[s2][s1].append(-td)\n",
    "'''\n",
    "\n",
    "\n",
    "lens = []\n",
    "for s1 in time_delta:\n",
    "    for s2 in time_delta[s1]:\n",
    "        lens.append(len(time_delta[s1][s2]))\n",
    "\n",
    "np.histogram(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"temp_storage/received_filtered.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dict(received), f)\n",
    "\n",
    "with open(\"temp_storage/sensors_filtered.pickle\", \"wb\") as f:\n",
    "    pickle.dump(sensors, f)\n",
    "\n",
    "with open(\"temp_storage/time_delta.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dict(time_delta), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas Baege\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipyparallel\\util.py:609: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if V(jupyter_client.__version__) < V('5.0'):\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import position_estimator\n",
    "from position_estimator import GeoPoint\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "from position_estimator import GeoPoint\n",
    "import traceback\n",
    "import ipyparallel as ipp\n",
    "import util\n",
    "\n",
    "with open(\"temp_storage/received_filtered.pickle\", \"rb\") as f:\n",
    "    received = pickle.load(f)\n",
    "\n",
    "with open(\"temp_storage/sensors_filtered.pickle\", \"rb\") as f:\n",
    "    sensors = pickle.load(f)\n",
    "\n",
    "with open(\"temp_storage/time_delta.pickle\", \"rb\") as f:\n",
    "    time_delta = pickle.load(f)\n",
    "    #print(time_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Gaussians\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af8f3d8738c43dd8b2d421ef7e8c3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "time_delta_gaussians =  defaultdict(lambda: defaultdict(lambda: None))\n",
    "\n",
    "def calc_gaussian(i, j):\n",
    "    if len(time_delta[i][j]) > 1:\n",
    "        mean = statistics.mean(time_delta[i][j])\n",
    "        var = statistics.variance(time_delta[i][j], xbar=mean)\n",
    "        if var <= 1e-9 or True:\n",
    "            time_delta_gaussians[i][j] = (mean, var)\n",
    "            time_delta_gaussians[j][i] = (-mean, var)\n",
    "\n",
    "\n",
    "# initialize with directly known time deltas\n",
    "ij_collection = itertools.combinations(time_delta.keys(), 2)\n",
    "print(\"Calculating Gaussians\")\n",
    "for i, j in tqdm(ij_collection):\n",
    "    calc_gaussian(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.822736225255184\n",
      "(Latitude: 49.15917, Longitude: 15.1995, Altitude: 546.5, 'dump1090', '-1408236843')\n",
      "(Latitude: 48.180073, Longitude: 16.328741, Altitude: 204.0, 'dump1090', '-1408233302')\n",
      "8d77058c58cd8777576e175a7710\n",
      "Latitude: 47.99881, Longitude: 15.83253, Altitude: 12192.0\n",
      "1641790895.001 1641790895.56 0.5590000152587891\n",
      "[3487087.8158542505, 6267019.5422651665]\n",
      "8d77058c58cd800d5b738a631649\n",
      "Latitude: 48.07823, Longitude: 15.53096, Altitude: 12192.0\n",
      "1641790996.728 1641790997.252 0.5240001678466797\n",
      "[3487189.5489970837, 6267110.614837]\n"
     ]
    }
   ],
   "source": [
    "variances = [ time_delta_gaussians[i][j][1] for i,j in itertools.combinations(time_delta.keys(), 2) if i in time_delta_gaussians and j in time_delta_gaussians[i] and time_delta_gaussians[i][j] is not None ]\n",
    "max_variance = max(variances)\n",
    "print(max_variance)\n",
    "done = False\n",
    "for s1 in time_delta_gaussians:\n",
    "    for s2 in time_delta_gaussians[s1]:\n",
    "        if time_delta_gaussians[s1][s2][1] == max_variance:\n",
    "            print(s1)\n",
    "            print(s2)\n",
    "            for msg in received:\n",
    "                tmp = [e[1] for e in received[msg][\"sensors\"]]\n",
    "                if s1 in tmp and s2 in tmp:\n",
    "                    print(msg)\n",
    "                    print(received[msg][\"pos\"])\n",
    "                    print(received[msg][\"timeAtServer_min\"], received[msg][\"timeAtServer_max\"], received[msg][\"timeAtServer_max\"] - received[msg][\"timeAtServer_min\"])\n",
    "                    print([e[0] for e in received[msg][\"sensors\"] if e[1] in [s1, s2]])\n",
    "            done = True\n",
    "            break\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all time deltas between stations that picked up the same signal.\n",
    "We model the clock shifts using gaussian distributions, with some mean mu and standard deviation sigma\n",
    "\n",
    "Then, to get time delta probability distribution between two stations that didn't measure the same message, we convolute the probability density functions of stations with directly known time-delta\n",
    "\n",
    "Example:\n",
    "sensors A and B measured the same 100 messages, so we can directly model their time delta distribution function as: td_AB = Gauss(mu_AB, sigma_AB)\n",
    "Similarly, assume we estimate the density function for sensors B and C as Gauss(mu_BC, sigma_BC)\n",
    "\n",
    "Now, to get the density function for sensors A and C, we can convolute these two density functions:\n",
    "density function of time delta A-C = Gauss(mu_AB, sigma_AB) * Gauss(mu_BC, sigma_BC) = Gauss(mu_AB + mu_BC, sqrt(sigma_AB^2 + sigma_BC^2))\n",
    "\n",
    "We do this for all paths going from A to C, and sum up all PDFs to get the final PDF for the time delta between A and C.\n",
    "For efficiency, we could just do a \"shortest path\", where the path lengths are the sum of variances.\n",
    "This way, we just take the \"best\" path, with least uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Floyd's algorithm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeed395bd21442ae8b19362f50b04c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_cores = 16\n",
    "import concurrent.futures\n",
    "\n",
    "def floyd_adjust_min(k, i, j):\n",
    "    #if i == j or j == k or k == i:\n",
    "    #    return i, j, None\n",
    "    #if i not in time_delta_gaussians:\n",
    "    #    print(1, k, i, j)\n",
    "    #    return\n",
    "    #if k not in time_delta_gaussians:\n",
    "    #    print(2, k, i, j)\n",
    "    #    return\n",
    "    #if k not in time_delta_gaussians[i]:\n",
    "    #    print(3, k, i, j)\n",
    "    #    return\n",
    "    #if j not in time_delta_gaussians[k]:\n",
    "    #    print(4, k, i, j)\n",
    "    #    return\n",
    "    if i not in time_delta_gaussians or k not in time_delta_gaussians or k not in time_delta_gaussians[i] or j not in time_delta_gaussians[k]:\n",
    "        return i, j, None\n",
    "    if time_delta_gaussians[i][k] is not None and time_delta_gaussians[k][j] is not None:\n",
    "        new_variance = time_delta_gaussians[i][k][1] + time_delta_gaussians[k][j][1]\n",
    "        if time_delta_gaussians[i][j] is None or time_delta_gaussians[i][j][1] > new_variance:\n",
    "            new_mean = time_delta_gaussians[i][k][0] + time_delta_gaussians[k][j][0]\n",
    "            time_delta_gaussians[i][j] = (new_mean, new_variance)\n",
    "            time_delta_gaussians[j][i] = (-new_mean, new_variance)\n",
    "            #print(i, j, new_mean, new_variance)\n",
    "\n",
    "\n",
    "# floyd's algorithm\n",
    "print(\"Doing Floyd's algorithm\")\n",
    "for k in tqdm(time_delta.keys()):\n",
    "    #tdg = dict(time_delta_gaussians)\n",
    "    ij_collection = [(i, j) for i, j in itertools.combinations(time_delta.keys(), 2)]\n",
    "    #print(len(kij_collection))\n",
    "    #asyncresult = view.map_async(floyd_adjust_min, kij_collection)\n",
    "    #asyncresult.wait_interactive(return_when=concurrent.futures.ALL_COMPLETED)\n",
    "    #for i, j, val in asyncresult.get():\n",
    "    #    if val is None:\n",
    "    #        continue\n",
    "    #    time_delta_gaussians[i][j] = val\n",
    "    for i, j in ij_collection:\n",
    "        floyd_adjust_min(k, i, j)\n",
    "\n",
    "#print(time_delta_gaussians)\n",
    "tdg_dict = dict()\n",
    "for s1 in time_delta_gaussians:\n",
    "    if s1 not in tdg_dict:\n",
    "        tdg_dict[s1] = dict()\n",
    "    for s2 in time_delta_gaussians[s1]:\n",
    "        if time_delta_gaussians[s1][s2] is None:\n",
    "            continue\n",
    "        tdg_dict[s1][s2] = time_delta_gaussians[s1][s2]\n",
    "\n",
    "with open(\"temp_storage/time_delta_gaussians.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tdg_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta_gaussians = pickle.load(open(\"temp_storage/time_delta_gaussians.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Variance: 0.004229081859117333\n",
      "Median variance: 2.064691744487094e-10\n",
      "Mean nConnections: 266.2089818489943\n",
      "Median nConnections: 93.0\n",
      "nConnections modes: [1]\n"
     ]
    }
   ],
   "source": [
    "variances = [ time_delta_gaussians[i][j][1] for i,j in itertools.combinations(time_delta.keys(), 2) if i in time_delta_gaussians and j in time_delta_gaussians[i] and time_delta_gaussians[i][j] is not None ]\n",
    "num_conns = [ len(time_delta[i][j]) for i,j in itertools.combinations(time_delta.keys(), 2) if len(time_delta[i][j]) > 0]\n",
    "\n",
    "print(\"Mean Variance:\", statistics.mean(variances))\n",
    "print(\"Median variance:\", statistics.median(variances))\n",
    "#print(\"Variance modes:\", statistics.multimode(variances))\n",
    "\n",
    "print(\"Mean nConnections:\", statistics.mean(num_conns))\n",
    "print(\"Median nConnections:\", statistics.median(num_conns))\n",
    "print(\"nConnections modes:\", statistics.multimode(num_conns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5607951553820025\n",
      "(Latitude: 49.031386, Longitude: 2.06335, Altitude: 28.0, 'dump1090', '1408234760')\n",
      "(Latitude: 46.973057, Longitude: 18.916591, Altitude: 147.0, 'dump1090', '-1408235633')\n"
     ]
    }
   ],
   "source": [
    "max_variance = max(variances)\n",
    "print(max_variance)\n",
    "done = False\n",
    "for s1 in time_delta_gaussians:\n",
    "    for s2 in time_delta_gaussians[s1]:\n",
    "        if time_delta_gaussians[s1][s2][1] == max_variance:\n",
    "            print(s1)\n",
    "            print(s2)\n",
    "            for msg in received:\n",
    "                tmp = [e[1] for e in received[msg][\"sensors\"]]\n",
    "                if s1 in tmp and s2 in tmp:\n",
    "                    print(msg)\n",
    "                    print(received[msg][\"pos\"])\n",
    "                    print(received[msg][\"timeAtServer_min\"], received[msg][\"timeAtServer_max\"], received[msg][\"timeAtServer_max\"] - received[msg][\"timeAtServer_min\"])\n",
    "                    print([e[0] for e in received[msg][\"sensors\"] if e[1] in [s1, s2]])\n",
    "            done = True\n",
    "            break\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those time deltas, we can now check the aircraft locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cc4bce3b244c3392960ce00916caef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3929347.38323298+17797.24358111j  288158.62916994 +1357.67547611j\n",
      " 4999168.02562448+22762.82980613j]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "input must be a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUKASB~1\\AppData\\Local\\Temp/ipykernel_17968/607402073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mtarget_ecef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyVertexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mtarget_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeoPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mto_wgs84\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtarget_ecef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fail\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LUKASB~1\\AppData\\Local\\Temp/ipykernel_17968/607402073.py\u001b[0m in \u001b[0;36mto_wgs84\u001b[1;34m(x, y, z)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mecef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'geocent'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'WGS84'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'WGS84'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mlla\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latlong'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'WGS84'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'WGS84'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlla\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradians\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyproj\\transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(p1, p2, x, y, z, tt, radians, errcheck, skip_equivalent, always_xy)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     )\n\u001b[1;32m-> 1194\u001b[1;33m     return Transformer.from_proj(\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_equivalent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskip_equivalent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_xy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malways_xy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m     ).transform(xx=x, yy=y, zz=z, tt=tt, radians=radians, errcheck=errcheck)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyproj\\transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, xx, yy, zz, tt, radians, errcheck, direction, inplace)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \"\"\"\n\u001b[0;32m    736\u001b[0m         \u001b[1;31m# process inputs, making copies that support buffer API.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         \u001b[0minx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_copytobuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m         \u001b[0miny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_copytobuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mzz\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyproj\\utils.py\u001b[0m in \u001b[0;36m_copytobuffer\u001b[1;34m(xxx, inplace)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;31m# convert numpy array scalar to float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# (array scalars don't support buffer API)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_copytobuffer_return_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# Use C order when copying to handle arrays in fortran order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mARRAY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pyproj\\utils.py\u001b[0m in \u001b[0;36m_copytobuffer_return_scalar\u001b[1;34m(xxx)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLOAT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input must be a scalar\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: input must be a scalar"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import pyproj\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "M = np.diag([1, 1, 1, -1])\n",
    "\n",
    "@dataclass\n",
    "class Vertexer:\n",
    "\n",
    "    nodes: np.ndarray\n",
    "\n",
    "    # Defaults\n",
    "    v = 299792458\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Calculate valid input range\n",
    "        max = 0\n",
    "        min = 1E+10\n",
    "        centroid = np.average(self.nodes, axis = 0)\n",
    "        for n in self.nodes:\n",
    "            dist = np.linalg.norm(n - centroid)\n",
    "            if dist < min:\n",
    "                min = dist\n",
    "\n",
    "            for p in self.nodes:\n",
    "                dist = np.linalg.norm(n - p)\n",
    "\n",
    "                if dist > max:\n",
    "                    max = dist\n",
    "\n",
    "        max /= self.v\n",
    "        min /= self.v\n",
    "\n",
    "        #print(min, max)\n",
    "\n",
    "    def errFunc(self, point, times):\n",
    "        # Return RSS error\n",
    "        error = 0\n",
    "\n",
    "        for n, t in zip(self.nodes, times):\n",
    "            error += ((np.linalg.norm(n - point) / self.v) - t)**2\n",
    "\n",
    "        return error\n",
    "\n",
    "    def find(self, times):\n",
    "        def lorentzInner(v, w):\n",
    "            # Return Lorentzian Inner-Product\n",
    "            return np.sum(v * (w @ M), axis = -1)\n",
    "\n",
    "        A = np.append(self.nodes, times * self.v, axis = 1)\n",
    "        #print(A)\n",
    "        At = np.transpose(A)\n",
    "        #print(\"At\")\n",
    "        #print(At)\n",
    "        AtA = np.matmul(At, A)\n",
    "        #print(\"AtA\")\n",
    "        #print(AtA)\n",
    "        invAtA = np.linalg.inv(AtA)\n",
    "        #print(\"invAtA\")\n",
    "        #print(invAtA)\n",
    "        A_plus = np.matmul(invAtA, At)\n",
    "        #print(\"A_plus\")\n",
    "        #print(A_plus)\n",
    "\n",
    "\n",
    "        b = 0.5 * lorentzInner(A, A)\n",
    "        #print(\"b\")\n",
    "        #print(b)\n",
    "        #oneA = np.linalg.solve(A_plus, np.ones(4))\n",
    "        #invA = np.linalg.solve(A_plus, b)\n",
    "\n",
    "        oneA_plus = np.matmul(A_plus, np.ones(len(self.nodes)))\n",
    "        invA_plus = np.matmul(A_plus, b)\n",
    "\n",
    "        #print(\"oneA_plus\", oneA_plus.shape, np.ones(len(self.nodes)).shape)\n",
    "        #print(oneA_plus)\n",
    "        #print(\"invA_plus\")\n",
    "        #print(invA_plus)\n",
    "\n",
    "\n",
    "        solution = []\n",
    "        for Lambda in np.roots([ lorentzInner(oneA_plus, oneA_plus),\n",
    "                                (lorentzInner(oneA_plus, invA_plus) - 1) * 2,\n",
    "                                 lorentzInner(invA_plus, invA_plus),\n",
    "                                ]):\n",
    "            #X, Y, Z, T = M @ np.linalg.solve(, Lambda * np.ones(len(self.nodes)) + b)\n",
    "            X, Y, Z, T = np.matmul(A_plus, (b + Lambda * np.ones(len(self.nodes))))\n",
    "            if any(np.iscomplex([X, Y, Z, T])):\n",
    "                continue\n",
    "            solution.append(np.array([X,Y,Z]))\n",
    "            #print(\"Candidate:\", X, Y, Z, math.sqrt(X**2 + Y**2 + Z**2))\n",
    "\n",
    "        if not len(solution):\n",
    "            return\n",
    "        #print()\n",
    "        #print()\n",
    "        return min(solution, key = lambda err: self.errFunc(err, times))\n",
    "\n",
    "def to_ecef(geopoint):\n",
    "    ecef = pyproj.Proj(proj='geocent', ellps='WGS84', datum='WGS84')\n",
    "    lla = pyproj.Proj(proj='latlong', ellps='WGS84', datum='WGS84')\n",
    "    x, y, z = pyproj.transform(lla, ecef, geopoint.lon, geopoint.lat, geopoint.alt, radians=False)\n",
    "    #print(\"to_ecef:\", geopoint, \"->\", x, y, z)\n",
    "    return (x, y, z)\n",
    "\n",
    "def to_wgs84(x, y, z):\n",
    "    ecef = pyproj.Proj(proj='geocent', ellps='WGS84', datum='WGS84')\n",
    "    lla = pyproj.Proj(proj='latlong', ellps='WGS84', datum='WGS84')\n",
    "    lon, lat, alt = pyproj.transform(ecef, lla, x, y, z, radians=False)\n",
    "    return (lat, lon, alt)\n",
    "\n",
    "\n",
    "iterations = 0\n",
    "for msg, data in tqdm(received.items()):\n",
    "    if len(data[\"sensors\"]) < 4:\n",
    "        continue\n",
    "\n",
    "    iterations += 1\n",
    "    if iterations >= 1000:\n",
    "        break\n",
    "\n",
    "    td_base = None\n",
    "\n",
    "\n",
    "    best_variances = list()\n",
    "    for t1, s1 in data[\"sensors\"]:\n",
    "        if s1 not in time_delta_gaussians:\n",
    "            continue\n",
    "        var_sum = 0\n",
    "        non_none = 0\n",
    "        for t2, s2 in data[\"sensors\"]:\n",
    "            if s1 == s2:\n",
    "                continue\n",
    "            if s2 in time_delta_gaussians[s1]:\n",
    "                non_none += 1\n",
    "                var_sum += time_delta_gaussians[s1][s2][1]\n",
    "        best_variances.append((-non_none, var_sum, t1, s1))\n",
    "\n",
    "    best_variances.sort()\n",
    "    #print(best_variances)\n",
    "\n",
    "    if best_variances[0][0] > -4:\n",
    "        # less than four connected sensors\n",
    "        continue\n",
    "\n",
    "    if best_variances[3][1] > 1e-6:\n",
    "        # not accurate enough\n",
    "        continue\n",
    "\n",
    "    sensor_positions = list()\n",
    "    timestamps = list()\n",
    "\n",
    "    for _, _, timestamp, sensor in best_variances:\n",
    "        ecef_coords = to_ecef(sensor[0])\n",
    "        if td_base is None:\n",
    "            td_base = sensor\n",
    "            td = 0\n",
    "        else:\n",
    "            if sensor in time_delta_gaussians[td_base] and time_delta_gaussians[td_base][sensor] is not None:\n",
    "                td = time_delta_gaussians[td_base][sensor][0]\n",
    "            \n",
    "        sensor_positions.append(ecef_coords)\n",
    "        timestamps.append(timestamp + td)\n",
    "        if len(timestamps) == 6:\n",
    "            break\n",
    "    \n",
    "    timestamps = [ e - timestamps[0] for e in timestamps ]\n",
    "    #sensor_basepos = sensor_positions[0]\n",
    "    #sensor_positions = [ e - sensor_basepos for e in sensor_positions ]\n",
    "\n",
    "    #print(sensor_positions)\n",
    "    #print(timestamps)\n",
    "    \n",
    "    myVertexer = Vertexer(np.array(sensor_positions))\n",
    "    try:\n",
    "        target_ecef = myVertexer.find(np.array([[e] for e in timestamps]))\n",
    "        #target_ecef += sensor_basepos\n",
    "        print(target_ecef)\n",
    "        target_pos = GeoPoint(*to_wgs84(*target_ecef))\n",
    "    except:\n",
    "        target_ecef = myVertexer.find(np.array([[e] for e in timestamps]))\n",
    "        target_pos = GeoPoint(*to_wgs84(*target_ecef))\n",
    "        print(\"Fail\")\n",
    "        continue\n",
    "\n",
    "    #print(target_ecef)\n",
    "    print(\"Sensors:\")\n",
    "    for t, s in zip(timestamps, sensor_positions):\n",
    "        print(t,s)\n",
    "    print(\"Variances:\", [e[1] for e in best_variances[:4]])\n",
    "\n",
    "    print(\"Estimated Signal location:\", target_ecef)\n",
    "    print(\"True Signal location:     \", to_ecef(data[\"pos\"]))\n",
    "    print(\"Dist:\", np.linalg.norm(np.array(target_ecef) - np.array(to_ecef(data[\"pos\"]))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb048d5eccab4d94b62a867632cd4289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107934.77944910247 0 0\n",
      "27002.990904231556 80931.7889373966 24262739935879.336\n",
      "39.83166457153857 107894.94786448932 32346091626077.105\n",
      "5500.332380584441 102434.44722814579 30709074718397.113\n",
      "[[3836217.527465573, 665602.7446539975, 5035003.349590785, -32358032834734.316], [3733262.3243191987, 664027.3054950554, 5111427.4524335265, -32358032952410.555], [3817051.941483905, 677198.9789480256, 5047900.4088057615, -32358032858705.24], [3857557.2049890393, 712177.6983716807, 5012473.618069542, -32358032882589.51]]\n",
      "(2.7176898806900472e-24, -2.0000391783716394, 145337506953428.06)\n",
      "[7.35933556e+23 7.26673300e+13]\n",
      "[ 6.03090190e+11  3.25442863e+11  1.00137540e+12 -2.27432197e+10]\n",
      "[-7.07429151e+06 -1.51480945e+06 -9.64336103e+06 -5.24209481e+00]\n",
      "Distance: 20657006.93331343\n",
      "11318.211749547161 0 0\n",
      "1318.0034147165716 10000.208766541553 2997987166634.64\n",
      "23032.327934230678 -11714.115262612577 -3511803407873.94\n",
      "39144.55562034063 -27826.344505311892 -8342128216402.246\n",
      "[[4066727.8986526043, 588886.5684694499, 4861884.644498041, -3393114520561.2236], [4217739.550081397, 551148.1178633895, 4736940.279445242, -3393114649984.9146], [4162597.0476090405, 686254.9948784075, 4767950.292817591, -3393114796991.137], [4166754.100845929, 747838.3420977398, 4755420.505303479, -3393114330337.386]]\n",
      "(2.078176028807519e-20, -1.9998532164692315, 259944191607.17435)\n",
      "[9.62311751e+19 1.29981636e+11]\n",
      "[-9.01163605e+09 -1.30606661e+09 -1.04665067e+10 -2.83867517e+07]\n",
      "[-3.12528856e+05 -3.62954727e+04 -4.01212691e+05 -6.96542007e+00]\n",
      "Distance: 20321176.17790737\n",
      "11318.211277914234 0 0\n",
      "519.1892073927447 10799.021916710002 3237465324406.363\n",
      "162032.62300170772 -150714.41172397407 -45183043946754.2\n",
      "96.5400918154046 11221.671069287822 3364172352729.2847\n",
      "[[4066727.8986526043, 588886.5684694499, 4861884.644498041, -3393114379169.229], [3899498.4156247852, 454716.81523570465, 5009897.067637574, -3393114333057.7056], [4065556.711561537, 590564.4463489464, 4862648.841612322, -3393114379115.09], [3966445.9603306693, 376364.4430885889, 4963924.10763969, -3393114344150.1704]]\n",
      "(1.9638106310459775e-20, -2.1330978603751545, 2.5600602615246505e+18)\n",
      "[1.07406621e+20 1.21372285e+18]\n",
      "[-1.16125785e+10  7.48155250e+09  4.89781738e+09 -3.16415976e+07]\n",
      "[ 8.57292705e+08  2.08132752e+08  1.28420238e+09 -3.54597212e+05]\n",
      "Distance: 1000000000.0\n",
      "18001.038363039494 0 0\n",
      "18001.038494821638 1.0326278532682113e-05 3095.740423305404\n",
      "18001.03833342623 -2.828509230923502e-06 -847.9657348142463\n",
      "23032.328000998124 -4847.216371550794 -1453158910485.0537\n",
      "[[4071754.159671951, 620220.3306681438, 4853891.959735837, -5396575537407.906], [4164797.149096841, 676608.4610889065, 4767027.816535368, -5396575580010.939], [4062692.9846926206, 588428.2552289315, 4865526.787900107, -5396575527682.106], [4162597.0476090405, 686254.9948784075, 4767950.292817591, -5451759314396.401]]\n",
      "(2.4792994913375242e-14, -1.0054140704048433, 9976055793581.438)\n",
      "[2.32340753e+13 1.73182692e+13]\n",
      "[ 4.44942865e+06  5.94329565e+05  5.13005923e+06 -2.03440786e-02]\n",
      "[ 3.84441786e+06  5.09434250e+05  4.42690257e+06 -2.28177374e-02]\n",
      "Distance: 441564.15955234546\n"
     ]
    }
   ],
   "source": [
    "import pyproj\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def to_ecef(geopoint):\n",
    "    ecef = pyproj.Proj(proj='geocent', ellps='WGS84', datum='WGS84')\n",
    "    lla = pyproj.Proj(proj='latlong', ellps='WGS84', datum='WGS84')\n",
    "    x, y, z = pyproj.transform(lla, ecef, geopoint.lon, geopoint.lat, geopoint.alt, radians=False)\n",
    "    return (x, y, z)\n",
    "\n",
    "def to_wgs84(x, y, z):\n",
    "    ecef = pyproj.Proj(proj='geocent', ellps='WGS84', datum='WGS84')\n",
    "    lla = pyproj.Proj(proj='latlong', ellps='WGS84', datum='WGS84')\n",
    "    lon, lat, alt = pyproj.transform(ecef, lla, x, y, z, radians=False)\n",
    "    return (lat, lon, alt)\n",
    "\n",
    "def lorentz_inner(u, v):\n",
    "    assert len(u) == len(v) == 4\n",
    "    return u[0]*v[0] + u[1]*v[1] + u[2]*v[2] - u[3]*v[3]\n",
    "\n",
    "\n",
    "iterations = 0\n",
    "\n",
    "for msg, data in tqdm(received.items()):\n",
    "    #print(time_delta_gaussians)\n",
    "    #break\n",
    "\n",
    "    if len(data[\"sensors\"]) < 4:\n",
    "        continue\n",
    "\n",
    "    iterations += 1\n",
    "    if iterations >= 5:\n",
    "        break\n",
    "\n",
    "    #valid_sensors = [ data[\"sensors\"][0] ]\n",
    "    #for s in data[\"sensors\"][1:]:\n",
    "    #    if s[]\n",
    "\n",
    "    # Bancroft method\n",
    "    B = list()\n",
    "    a = list()\n",
    "    td_base = None\n",
    "\n",
    "\n",
    "    best_variances = list()\n",
    "    for t1, s1 in data[\"sensors\"]:\n",
    "        var_sum = 0\n",
    "        non_none = 0\n",
    "        for t2, s2 in data[\"sensors\"]:\n",
    "            if s1 == s2:\n",
    "                continue\n",
    "            if s2 in time_delta_gaussians[s1]:\n",
    "                non_none += 1\n",
    "                var_sum += time_delta_gaussians[s1][s2][1]\n",
    "        best_variances.append((-non_none, var_sum, t1, s1))\n",
    "\n",
    "    best_variances.sort()\n",
    "\n",
    "    if best_variances[0][0] > -4:\n",
    "        # less than four connected sensors\n",
    "        continue\n",
    "\n",
    "    for _, _, timestamp, sensor in best_variances:\n",
    "        ecef_coords = to_ecef(sensor[0])\n",
    "        if td_base is None:\n",
    "            td_base = sensor\n",
    "            td = 0\n",
    "        else:\n",
    "            if sensor in time_delta_gaussians[td_base] and time_delta_gaussians[td_base][sensor] is not None:\n",
    "                td = time_delta_gaussians[td_base][sensor][0]\n",
    "            \n",
    "        print(timestamp, td, td*C)\n",
    "        B.append([*ecef_coords, C*(-timestamp - td)])\n",
    "        a.append(0.5*(ecef_coords[0]**2 + ecef_coords[1]**2 + ecef_coords[2]**2 - td**2))\n",
    "        if len(a) >= 4:\n",
    "            break\n",
    "\n",
    "\n",
    "    e = [1] * 4#len(data[\"sensors\"])\n",
    "\n",
    "    print(B)\n",
    "    B_plus = np.matmul(np.linalg.inv(np.matmul(np.transpose(B), B)), np.transpose(B))\n",
    "    lambda_coefs = (lorentz_inner(np.matmul(B_plus,e), np.matmul(B_plus,e)), 2*(lorentz_inner(np.matmul(B_plus, a), np.matmul(B_plus,e)) - 1), lorentz_inner(np.matmul(B_plus,a), np.matmul(B_plus,a)))\n",
    "    lambda_roots = np.roots(lambda_coefs)\n",
    "\n",
    "    print(lambda_coefs)\n",
    "    print(lambda_roots)\n",
    "    #if len(lambda_roots) != 2:\n",
    "    #    continue\n",
    "    assert len(lambda_roots) == 2\n",
    "\n",
    "    best_dist = 1e9\n",
    "    for root in lambda_roots:\n",
    "        sol = np.matmul(B_plus, (a + root * np.array(e)))\n",
    "        print(sol)\n",
    "        dist = GeoPoint(*to_wgs84(*sol[:3])).dist(data[\"pos\"])\n",
    "        best_dist = min(best_dist, dist)\n",
    "\n",
    "    print(\"Distance:\", best_dist)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287b199b053340dcb4dfe802349d344f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum: [ 52.14    10.4601 120.    ]\n",
      "Broadcast pos: 52.67409 9.99306 10972.800000000001\n",
      "Estimated pos: 52.14 10.4601 120.0\n",
      "Dist: 68263.95609740308\n",
      "optimum: [  46.8914239    7.499006  1713.       ]\n",
      "Broadcast pos: 49.28895 7.45827 10363.2\n",
      "Estimated pos: 46.8914239 7.4990060000000085 1713.0\n",
      "Dist: 266743.4218124952\n",
      "optimum: [51.6303442  4.9487092 45.       ]\n",
      "Broadcast pos: 51.87618 7.56424 12192.0\n",
      "Estimated pos: 51.6303442 4.9487092 45.0\n",
      "Dist: 183067.81057760966\n",
      "optimum: [ 50.03496   8.24124 312.     ]\n",
      "Broadcast pos: 49.32985 7.43845 10972.800000000001\n",
      "Estimated pos: 50.03496 8.24124 312.0\n",
      "Dist: 98082.82992399957\n",
      "optimum: [ 51.43095016   6.92255878 119.56099701]\n",
      "Broadcast pos: 51.43611 7.27287 3268.98\n",
      "Estimated pos: 51.43095016479492 6.922558784484863 119.56099700927734\n",
      "Dist: 24570.580713169555\n",
      "optimum: [51.9899  4.3754 30.    ]\n",
      "Broadcast pos: 51.9912 -1.62483 11887.2\n",
      "Estimated pos: 51.9899 4.3754 30.0\n",
      "Dist: 412224.2846733337\n",
      "optimum: [51.282448  6.555248 85.      ]\n",
      "Broadcast pos: 49.17383 6.755 10972.800000000001\n",
      "Estimated pos: 51.282448 6.555248 85.0\n",
      "Dist: 235233.36287518073\n",
      "optimum: [ 48.8637  12.4492 350.    ]\n",
      "Broadcast pos: 50.24199 10.46802 10972.800000000001\n",
      "Estimated pos: 48.8637 12.4492 350.0\n",
      "Dist: 210134.11943322857\n",
      "optimum: [53.46991348  9.68182373  3.09816885]\n",
      "Broadcast pos: 53.94823 9.54186 12192.0\n",
      "Estimated pos: 53.469913482666016 9.68182373046875 3.0981688499450684\n",
      "Dist: 55390.426315951765\n",
      "optimum: [ 49.87382   8.66087 178.     ]\n",
      "Broadcast pos: 50.65498 5.12512 11414.76\n",
      "Estimated pos: 49.87382 8.66087 178.0\n",
      "Dist: 266863.84178829053\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "def estimate_position(sensors, time_delta_gaussians):\n",
    "    assert len(sensors) >= 4\n",
    "\n",
    "    # we want to find a position p, for which we want to minimize some objective function.\n",
    "    # this objective function is subject to the time deltas,\n",
    "    # and the distances from the estimated position and the sensor positions\n",
    "    # also, we should consider the variances in the time delta distributions:\n",
    "    # if some time delta probability distribution has very big variance,\n",
    "    # we can't trust that sensor to the same degree as a sensor with a small time delta variance\n",
    "\n",
    "    # attempt 1:\n",
    "    def residual_error(p):\n",
    "        p = position_estimator.GeoPoint(*p)\n",
    "        #print(\"p:\", p.lat, p.lon, p.alt)\n",
    "        err = 0\n",
    "        for i,j in itertools.combinations(range(len(sensors)), 2):\n",
    "            if time_delta_gaussians[sensors[i]][sensors[j]] is None:\n",
    "                continue\n",
    "\n",
    "            dist_i = p.dist(sensors[sensors[i]][0])\n",
    "            dist_j = p.dist(sensors[sensors[j]][0])\n",
    "            t_i = sensors[i][0] - dist_i / C\n",
    "            t_j = sensors[j][0] - dist_j / C\n",
    "            #print(sensors[i], sensors[j], t_i, t_j, time_delta_gaussians[sensors[i]][sensors[j]])\n",
    "            e = (t_i - t_j - time_delta_gaussians[sensors[i]][sensors[j]][0]) ** 2 / time_delta_gaussians[sensors[i]][sensors[j]][1]\n",
    "            err += e\n",
    "        #print(err)\n",
    "        return err\n",
    "\n",
    "    def residual_error2(p):\n",
    "        p = position_estimator.GeoPoint(*p)\n",
    "        err = 0\n",
    "        true_t = sensor_timestamps[0] - p.dist(sensors[0][1][0]) / C\n",
    "        for i in range(1, len(sensors)):\n",
    "            t = sensors[i][0] - p.dist(sensors[sensors[i]][0]) / C\n",
    "            err += true_t - t - time_delta_gaussians[sensors[0]][sensors[i]][0]\n",
    "        #print(err, len(sensors), err/len(sensors))\n",
    "        return err\n",
    "\n",
    "    def residual_error3(p):\n",
    "        p = position_estimator.GeoPoint(*p)\n",
    "        err = 0\n",
    "        for assumed_true in range(len(sensors)):\n",
    "            true_t = sensor_timestamps[sensors[assumed_true]] - p.dist(sensors[sensors[assumed_true]][0]) / C\n",
    "            for i in range(len(sensors)):\n",
    "                if i == assumed_true:\n",
    "                    continue\n",
    "                t = sensors[i][0] - p.dist(sensors[sensors[i]][0]) / C\n",
    "                err += true_t - t - time_delta_gaussians[sensors[assumed_true]][sensors[i]][0]\n",
    "            #print(err, len(sensors), err/len(sensors))\n",
    "            return err\n",
    "\n",
    "    def residual_error4(p):\n",
    "        p = position_estimator.GeoPoint(*p)\n",
    "        # choose 4 best time_delta distributions (smallest variances)\n",
    "        val = (100000, None)\n",
    "        for a, b, c, d in itertools.combinations(range(len(sensors)), 4):\n",
    "            s = sum([time_delta_gaussians[sensors[e]][sensors[f]][1] for e,f in itertools.combinations([a,b,c,d],2)])\n",
    "            val = min(val, (s, (a,b,c,d)))\n",
    "        err = 0\n",
    "        for i,j in itertools.combinations(val[1], 2):\n",
    "            #print(i,j, sensors[i], sensors[j])\n",
    "            ti = sensors[i][0] - p.dist(sensors[sensors[i]][0]) / C\n",
    "            tj = sensors[j][0] - p.dist(sensors[sensors[j]][0]) / C\n",
    "            err += ti - tj - time_delta_gaussians[sensors[i]][sensors[j]][0]\n",
    "        return err\n",
    "\n",
    "\n",
    "    bounds = scipy.optimize.Bounds([-90, -180, 0], [90, 180, 100000])\n",
    "    method = 'L-BFGS-B'\n",
    "    optimum = scipy.optimize.minimize(residual_error, [sensors[0][1][0].lat, sensors[0][1][0].lon, sensors[0][1][0].alt], method=method, bounds=bounds).x\n",
    "    print(\"optimum:\", optimum)\n",
    "    return GeoPoint(*optimum)\n",
    "\n",
    "\n",
    "it = 0\n",
    "for msg in tqdm(received):\n",
    "    if len(received[msg][\"sensors\"]) < 4:\n",
    "        continue\n",
    "    \n",
    "    estimated_pos = estimate_position(received[msg][\"sensors\"], time_delta_gaussians)\n",
    "    received[msg][\"estimated_pos\"] = estimated_pos\n",
    "    print(\"Broadcast pos:\", received[msg][\"pos\"].lat, received[msg][\"pos\"].lon, received[msg][\"pos\"].alt)\n",
    "    print(\"Estimated pos:\", received[msg][\"estimated_pos\"].lat, received[msg][\"estimated_pos\"].lon, received[msg][\"estimated_pos\"].alt)\n",
    "    print(\"Dist:\", received[msg][\"pos\"].dist(received[msg][\"estimated_pos\"]))\n",
    "\n",
    "    it += 1\n",
    "    if it >= 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f83f7d2bec24b1c01f80f56dfc3ff5e19c44b6c9892506c9ab7d9e0c90a9b548"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
